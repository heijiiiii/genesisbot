from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional, Any
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
import os
import json
import logging
import gc
import ast
import numpy as np
from pathlib import Path
import re

# gen_chatbot.pyì—ì„œ í•„ìš”í•œ ê²ƒë“¤ ì„í¬íŠ¸
from gen_chatbot import (
    compiled_graph, 
    config,
    llm,
    AgentState,
    cohere_embeddings,
    client
)
from langchain_core.messages import HumanMessage, AIMessage

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Genesis G80 AI Assistant API",
    description="ì œë„¤ì‹œìŠ¤ G80 ë§¤ë‰´ì–¼ ì „ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸",
    version="1.0.0"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²° í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš© - í”„ë¡œë•ì…˜ì—ì„œëŠ” ì‹¤ì œ ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ (ì›ë³¸ app.py ê¸°ë°˜ìœ¼ë¡œ ê°œì„ )
class ChatRequest(BaseModel):
    message: str
    history: Optional[List[Dict[str, str]]] = []
    debug_mode: Optional[bool] = False

class ChatResponse(BaseModel):
    answer: str
    context: str = ""
    images: Optional[List[Dict[str, Any]]] = None
    debug_info: Optional[Dict[str, Any]] = None
    success: bool = True
    error: Optional[str] = None

class SearchRequest(BaseModel):
    query: str
    page_filter: Optional[str] = None
    limit: Optional[int] = 5

# ë©”ëª¨ë¦¬ì— ëŒ€í™” ì„¸ì…˜ ì €ì¥
chat_sessions = {}

# ì´ë¯¸ì§€ ê´€ë ¨ì„± ë¶„ì„ í•¨ìˆ˜ (metadata ì™„ì „ ì œê±°)
def analyze_image_relevance(image_url, query_text):
    """ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ í…ìŠ¤íŠ¸ì˜ ê´€ë ¨ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. (metadata ì‚¬ìš© ì•ˆí•¨)"""
    try:
        query_embedding = cohere_embeddings.embed_query(query_text)
        
        img_embedding = None
        try:
            # image_url ì»¬ëŸ¼ìœ¼ë¡œë§Œ ê²€ìƒ‰ (metadata ì‚¬ìš© ì•ˆí•¨)
            resp = client.table("image_embeddings").select("embedding").eq("image_url", image_url).execute()
            if resp and resp.data and len(resp.data) > 0:
                if 'embedding' in resp.data[0]:
                    embedding_str = resp.data[0]['embedding']
                    if isinstance(embedding_str, str):
                        try:
                            embedding_str = embedding_str.replace(" ", "")
                            img_embedding = ast.literal_eval(embedding_str)
                        except:
                            logger.warning(f"ì„ë² ë”© ë¬¸ìì—´ íŒŒì‹± ì‹¤íŒ¨: {embedding_str[:50]}...")
                            img_embedding = None
                    else:
                        img_embedding = embedding_str
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì„ë² ë”© ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        # ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
        embedding_similarity = 0.5
        if img_embedding:
            try:
                norm_q = np.linalg.norm(query_embedding)
                norm_img = np.linalg.norm(img_embedding)
                if norm_q > 0 and norm_img > 0:
                    embedding_similarity = np.dot(query_embedding, img_embedding) / (norm_q * norm_img)
                    embedding_similarity = (embedding_similarity + 1) / 2  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
                    embedding_similarity = float(embedding_similarity)
            except Exception as e:
                logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
                embedding_similarity = 0.5
        
        # URLì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ (metadata ëŒ€ì‹  URL íŒ¨í„´ ì‚¬ìš©)
        vertical_position = 0.5
        url_lower = image_url.lower()
        if "top" in url_lower or "upper" in url_lower:
            vertical_position = 0.2
        elif "bottom" in url_lower or "lower" in url_lower or "bot" in url_lower:
            vertical_position = 0.8
        elif "mid" in url_lower or "middle" in url_lower:
            vertical_position = 0.5
        
        result = {
            "vertical_position": float(vertical_position),
            "relevance_score": float(embedding_similarity),
            "embedding_similarity": float(embedding_similarity)
        }
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del query_embedding
        del img_embedding
        gc.collect()
        
        return result
        
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            "vertical_position": 0.5,
            "relevance_score": 0.5,
            "embedding_similarity": 0.5
        }

def get_page_images(page, query_text, limit=3):
    """í˜ì´ì§€ë³„ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•˜ê³  ê´€ë ¨ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        # URL íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ (p{page}_ íŒ¨í„´)
        resp = client.table("image_embeddings").select("*").ilike("image_url", f"%p{page}_%").execute()
        
        if not resp or not resp.data or len(resp.data) == 0:
            logger.warning(f"í˜ì´ì§€ {page}ì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        page_images = []
        for item in resp.data:
            if 'image_url' in item and item['image_url']:
                img_url = item['image_url']
                
                # URLì—ì„œ í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ (pìˆ«ì_ íŒ¨í„´)
                page_match = re.search(r'p(\d+)_', img_url)
                if page_match:
                    img_page = page_match.group(1)
                else:
                    img_page = str(page)  # íŒ¨í„´ì„ ì°¾ì§€ ëª»í•˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                
                # ì´ë¯¸ì§€ ê´€ë ¨ì„± ë¶„ì„
                img_analysis = analyze_image_relevance(img_url, query_text)
                
                # ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
                image_info = {
                    "url": img_url,
                    "page": img_page,
                    "relevance_score": float(img_analysis["relevance_score"]),
                    "text_relevance": float(img_analysis["embedding_similarity"]),
                    "score": float(0.7 * img_analysis["relevance_score"] + 0.3)
                }
                
                page_images.append(image_info)
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        page_images.sort(key=lambda x: x["relevance_score"], reverse=True)
        return page_images[:limit]
        
    except Exception as e:
        logger.error(f"í˜ì´ì§€ ì´ë¯¸ì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return []

@app.post("/api/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """ê°œì„ ëœ ì±„íŒ… API ì—”ë“œí¬ì¸íŠ¸"""
    try:
        logger.info(f"ìƒˆë¡œìš´ ì±„íŒ… ìš”ì²­: {request.message[:50]}...")
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = "default_session"
        
        # ê¸°ì¡´ ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if session_id not in chat_sessions:
            chat_sessions[session_id] = {
                "messages": [],
                "context": "",
                "conversation_history": []
            }
        
        # í˜„ì¬ ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸°
        session = chat_sessions[session_id]
        
        # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
        session["messages"].append(HumanMessage(content=request.message))
        
        # LangGraphë¡œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
        state = {
            "messages": session["messages"],
            "context": "",
            "conversation_history": session["conversation_history"],
            "debug_info": {}
        }
        
        # AI ì‘ë‹µ ìƒì„±
        result = compiled_graph.invoke(state, config=config)
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì¶”ì¶œ
        last_ai_message = None
        for msg in reversed(result["messages"]):
            if isinstance(msg, AIMessage):
                last_ai_message = msg
                break
        
        if not last_ai_message:
            return ChatResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                success=False,
                error="No AI response found"
            )
        
        answer = last_ai_message.content
        context = result.get("context", "")
        
        # ë””ë²„ê·¸ ì •ë³´ì—ì„œ í˜ì´ì§€ ì •ë³´ ì¶”ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ê²€ìƒ‰
        images = []
        debug_info = result.get("debug_info", {})
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
        if "results" in debug_info:
            pages_found = set()
            for search_result in debug_info["results"][:3]:  # ìƒìœ„ 3ê°œ ê²°ê³¼
                page = search_result.get("page")
                if page and page != "unknown":
                    pages_found.add(str(page))
            
            # ê° í˜ì´ì§€ì—ì„œ ê´€ë ¨ ì´ë¯¸ì§€ ê²€ìƒ‰
            for page in list(pages_found)[:2]:  # ìµœëŒ€ 2ê°œ í˜ì´ì§€
                page_images = get_page_images(page, request.message, limit=2)
                images.extend(page_images)
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë‹µë³€ì— ì¶”ê°€ ì •ë³´ í¬í•¨
        if images:
            img_info_text = "\n\nğŸ“· ê´€ë ¨ ì´ë¯¸ì§€:"
            for i, img in enumerate(images[:3]):  # ìµœëŒ€ 3ê°œ
                img_info_text += f"\n[ì´ë¯¸ì§€ {i+1}] í˜ì´ì§€ {img['page']} (ê´€ë ¨ì„±: {img['relevance_score']:.2f})"
            answer += img_info_text
        
        # ì„¸ì…˜ ì—…ë°ì´íŠ¸
        session["messages"] = result["messages"]
        session["conversation_history"] = result.get("conversation_history", [])
        
        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì œí•œ
        if len(session["messages"]) > 20:
            session["messages"] = session["messages"][-20:]
        
        logger.info("ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
        return ChatResponse(
            answer=answer,
            context=context,
            images=images if images else None,
            debug_info=debug_info if request.debug_mode else None,
            success=True
        )
            
    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ChatResponse(
            answer="ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            success=False,
            error=str(e)
        )

@app.post("/api/search")
async def search_endpoint(request: SearchRequest):
    """í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ê°„ë‹¨í•œ LangGraph í˜¸ì¶œë¡œ ê²€ìƒ‰
        state = {
            "messages": [HumanMessage(content=request.query)],
            "context": "",
            "conversation_history": [],
            "debug_info": {}
        }
        
        result = compiled_graph.invoke(state, config=config)
        debug_info = result.get("debug_info", {})
        
        # ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
        results = debug_info.get("results", [])
        if request.limit and request.limit < len(results):
            results = results[:request.limit]
        
        return {"results": results, "query": request.query}
        
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "message": "Genesis G80 AI Assistant API is running",
        "active_sessions": len(chat_sessions),
        "version": "1.0.0"
    }

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Genesis G80 AI Assistant API",
        "docs": "/docs",
        "health": "/health",
        "endpoints": {
            "chat": "/api/chat",
            "search": "/api/search",
            "reset": "/api/reset"
        }
    }

@app.post("/api/reset")
async def reset_session():
    """ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”"""
    session_id = "default_session"
    if session_id in chat_sessions:
        del chat_sessions[session_id]
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    
    return {"message": "ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤", "success": True}

# ë©”ëª¨ë¦¬ ì •ë¦¬ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def clean_memory_after_request(request, call_next):
    """ìš”ì²­ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬"""
    response = await call_next(request)
    
    # ì£¼ê¸°ì ìœ¼ë¡œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
    if hasattr(clean_memory_after_request, 'request_count'):
        clean_memory_after_request.request_count += 1
    else:
        clean_memory_after_request.request_count = 1
    
    # 10ë²ˆë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    if clean_memory_after_request.request_count % 10 == 0:
        gc.collect()
        logger.info("ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰ë¨")
    
    return response

# ì„œë²„ ì‹œì‘
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    logger.info(f"Genesis G80 API ì„œë²„ë¥¼ í¬íŠ¸ {port}ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info"
    ) 